{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning  reproducibility project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/je3we3/d-gex-reproduction/blob/main/Deep_learning_reproducibility_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHvtZrrbwIRp"
      },
      "source": [
        "##IMPORTS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDJTrkzHro2h",
        "outputId": "80d42809-db66-4dfd-ae63-9004a66302c1"
      },
      "source": [
        "##DOWNLOAD DATASET FROM GOOGLE DRIVE\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1ZrO4Zm14keIcxrdUkfzL3J54voERO1Zt' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "\n",
        "filepath = '/root/data/samples.mat'\n",
        "arrays = {}\n",
        "f = h5py.File(filepath)\n",
        "for k, v in f.items():\n",
        "    arrays[k] = np.array(v)\n",
        "data = arrays['samples']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: samples.mat, id: 1AwSM8RHUI4f7W0VcqDAZYJ0C9hTYfJwA\n",
            "downloading to /root/data/samples.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdyscXlhjCjO"
      },
      "source": [
        "##MODEL\n",
        "#Constants\n",
        "MOMENTUM = 0.5\n",
        "LEARNING_RATE_FACTOR = 1e-2\n",
        "LEARNING_RATE_START = 5e-4 * LEARNING_RATE_FACTOR\n",
        "LEARNING_RATE_MIN = 1e-5 * LEARNING_RATE_FACTOR\n",
        "LEARNING_RATE_DECAY = 0.9\n",
        "MAX_EPOCHS = 200\n",
        "BATCH_SIZE = 200\n",
        "DROPOUT_LEARNING_SCALE = 3\n",
        "\n",
        "#Model class\n",
        "class Net(nn.Module):\n",
        "  #Class specific constants\n",
        "  INPUT_SIZE = 943 #Landmark genes\n",
        "  HIDDEN_SIZE = 3000 #ook 6000 en 9000\n",
        "  OUTPUT_SIZE = 4760 #9520 #Target genes\n",
        "  DROPOUT_RATE = 0.1\n",
        "  OUTPUT_INIT = 1e-4\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(self.INPUT_SIZE, self.HIDDEN_SIZE)\n",
        "    dist = math.sqrt(6)/math.sqrt(self.INPUT_SIZE + self.HIDDEN_SIZE)\n",
        "    nn.init.uniform_(self.hidden1.weight, a=-dist, b=dist)\n",
        "\n",
        "    self.dropout1 = nn.Dropout2d(self.DROPOUT_RATE)\n",
        "    \n",
        "    self.output = nn.Linear(self.HIDDEN_SIZE, self.OUTPUT_SIZE)\n",
        "    nn.init.uniform_(self.output.weight, a=-self.OUTPUT_INIT, b=self.OUTPUT_INIT)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.hidden1(x)\n",
        "      x = torch.tanh(x)\n",
        "      x = self.dropout1(x)\n",
        "      x = self.output(x)\n",
        "\n",
        "      return x\n",
        "    \n",
        "net = Net()\n",
        "training_loss_func = nn.MSELoss(reduction = 'sum')\n",
        "test_loss_func = nn.L1Loss()\n",
        "optimizer = optim.SGD([{'params': [param for name, param in net.named_parameters() if 'dropout1' not in name]}, {'params': net.dropout1.parameters(), 'lr': LEARNING_RATE_START * DROPOUT_LEARNING_SCALE}], lr=LEARNING_RATE_START, momentum = MOMENTUM)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_DECAY, patience = 0, threshold = 0, min_lr = LEARNING_RATE_MIN) #Set metric for learning rate decay in scheduler.step\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhNY24XCsJpw"
      },
      "source": [
        "##PREP DATA\n",
        "#Normalize data\n",
        "data_mean = data.mean(axis=0)\n",
        "data_std = data.std(axis=0) + 1e-3\n",
        "data_norm = (data - data_mean.reshape((1, 10463)))/data_std.reshape((1, 10463))\n",
        "\n",
        "#Divide into training and test set\n",
        "x = np.random.rand(data_norm.shape[0], data_norm.shape[1])\n",
        "np.random.shuffle(x)\n",
        "training, test = x[:round(0.8*data_norm.shape[0]),:], x[round(0.8*data_norm.shape[0]):,:]\n",
        "\n",
        "#Set correct shape\n",
        "#Use second half of the dataset to speed up training and testing\n",
        "training_x, training_y = training[:,:943], training[:,5703:10463]\n",
        "test_x, test_y = test[:,:943], test[:,5703:10463]\n",
        "\n",
        "# #Uncomment to use entire dataset\n",
        "# training_x, training_y = training[:,:943], training[:,943:]\n",
        "# test_x, test_y = test[:,:943], test[:,943:]\n",
        "\n",
        "# Create training and test tensors\n",
        "tensors_train = torch.tensor(training_x).float(), torch.tensor(training_y).float()\n",
        "tensors_test = torch.tensor(test_x).float(), torch.tensor(test_y).float()\n",
        "\n",
        "# Create training set and test set from tensors\n",
        "train_set = torch.utils.data.TensorDataset(*tensors_train)\n",
        "test_set = torch.utils.data.TensorDataset(*tensors_test)\n",
        "\n",
        "# Create dataloaders from the training and test set for easier iteration over the data\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPw4gYMXgLoj",
        "outputId": "e7addf08-d7c9-4985-90d6-bac2c7da4aae"
      },
      "source": [
        "##TRAIN AND TEST\n",
        "#Define train and test functions\n",
        "def train(train_loader, net, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Trains network for one epoch in batches.\n",
        "\n",
        "    Args:\n",
        "        train_loader: Data loader for training set.\n",
        "        net: Neural network model.\n",
        "        optimizer: Optimizer (e.g. SGD).\n",
        "        criterion: Loss function (e.g. cross-entropy loss).\n",
        "    \"\"\"\n",
        "  \n",
        "    avg_loss = 0\n",
        "\n",
        "    # iterate through batches\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimizer\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # keep track of loss\n",
        "        avg_loss += loss\n",
        "\n",
        "    return avg_loss/len(train_loader)\n",
        "        \n",
        "def test(test_loader, net, criterion):\n",
        "    \"\"\"\n",
        "    Evaluates network in batches.\n",
        "\n",
        "    Args:\n",
        "        test_loader: Data loader for test set.\n",
        "        net: Neural network model.\n",
        "        criterion: Loss function (e.g. cross-entropy loss).\n",
        "    \"\"\"\n",
        "\n",
        "    avg_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Use torch.no_grad to skip gradient calculation, not needed for evaluation\n",
        "    with torch.no_grad():\n",
        "        # iterate through batches\n",
        "        for data in test_loader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            # forward pass\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # keep track of loss\n",
        "            avg_loss += loss\n",
        "\n",
        "    return avg_loss/len(test_loader)\n",
        "\n",
        "#Train and test model\n",
        "#Create array to save losses in\n",
        "train_loss = np.empty(MAX_EPOCHS)\n",
        "test_loss = np.empty(MAX_EPOCHS)\n",
        "for epoch in tqdm(range(MAX_EPOCHS)):\n",
        "    # Train on data\n",
        "    train_loss[epoch] = train(train_loader,net,optimizer,training_loss_func)\n",
        "\n",
        "    # Test on data\n",
        "    test_loss[epoch] = test(test_loader,net,test_loss_func)\n",
        "\n",
        "    #Adapt learning rate\n",
        "    scheduler.step(test_loss[epoch])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [2:03:45<00:00, 37.13s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE5ooeGWuV0j",
        "outputId": "a34cedef-25a7-40bf-8563-bb9009b8db16"
      },
      "source": [
        "test_loss[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25030842423439026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfc0Z5zvCyif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737312b0-3417-4e94-bf57-f4884a02195a"
      },
      "source": [
        "##SAVE AND LOAD MODEL\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZHgEFgCgjSD"
      },
      "source": [
        "##SAVING PART\n",
        "torch.save(net.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDsgGmfAb6W1",
        "outputId": "b0939c8a-4a32-4be8-f5bf-2010cc36e2f4"
      },
      "source": [
        "##LOADING PART\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (hidden1): Linear(in_features=943, out_features=3000, bias=True)\n",
              "  (dropout1): Dropout2d(p=0.1, inplace=False)\n",
              "  (output): Linear(in_features=3000, out_features=9520, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9kvc1i7l_BR"
      },
      "source": [
        "**Links:**\n",
        "\n",
        "**Paper**\n",
        "\n",
        "https://academic.oup.com/bioinformatics/article/32/12/1832/1743989?login=true#84798257\n",
        "\n",
        "**Data**\n",
        "\n",
        "https://cbcl.ics.uci.edu/public_data/D-GEX/"
      ]
    }
  ]
}